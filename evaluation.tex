\section{Evaluation}
\label{sec:results}
\subsection{Experimental Setup}
%
We implemented the above mentioned transformations as a wrapper around the Symbolic PathFinder~\cite{spf} tool.
%
To make use of region summaries in Symbolic PathFinder, we use an existing feature of SPF named \textit{listener}.
%
A listener is a method defined within SPF that is called for every bytecode instruction executed by SPF.
%
\tool\ adds a path merging listener to SPF that, on every program location to be executed, checks if the next
instruction is a conditional branch instruction with at least one symbolic operand.
%
On finding such a symbolic branch condition, \tool\ attempts to compute a static summary of all multi-path
regions in the method which contains the current program location.
%
After this Just-In-Time static analysis, if \tool\ summarized the multi-path region that begins at the current program
location, \tool\ instantiates the region summary corresponding to the current program location by reading inputs from
and writing outputs to the stack and the heap.
%
Finally, it conjuncts the instantiated region summary with the path condition and resumes symbolic execution at the
bytecode offset of the end of the region.
%
\tool\ wraps around SPF and can be configured to either run SPF without any path merging or run SPF with the
following path-merging features enabled.

\tool\ summarizes multi-path regions with a single exit point and instantiates them if they are encountered.
This includes multi-path regions that have local, stack, field, or array outputs.
%
\tool\ substitutes local inputs into the Ranger IR representation of the multi-path region, and constructs SSA form
Ranger IR for all field and array accesses in the region using its instantiation-time context.
%
The SSA form representation of all field and array accesses allows the Ranger IR to be simplified uniformly across all
variable types which reduces the size of the region summary and improves performance.
%
While our current implementation of \tool\ cannot instantiate summaries with symbolic object and array
references, it is capable of summarizing reads and writes to arrays with symbolic indices.
%
\tool\ instantiates all multi-path region
summaries that make method calls which have also been statically summarized.
%
Method summaries are inlined into
the multi-path region summary based on the instantiation-time type of the method.
%
\tool\ uses single-path cases to allow regions to have more than one exit point.
%
These exit points take the form of new object allocations and exceptional behavior present in the region.
%
\tool\ converts multiple exit points that return
control flow from the region to its caller into a single control flow-returning exit point.
%
This feature allows summarization of multiple {\tt return} instructions in a region into a single control-flow
returning exit point.
%
Instead of a single return value, such an exit point returns a formula to its caller, which predicates
each return value on its corresponding condition in the region.

We used the control-flow graph recovered by Wala~\cite{Wala} to bootstrap our static statement recovery process.
%
%While we found our static statement recovery was capable of summarizing thousands of regions in Java library code, many
%of these summaries could not be instantiated due to JPF\rq s use of native peers~\cite{jpf-mji}.
%
%To avoid these unnecessary instantiation failures and target our static statement recovery towards the benchmark code,
%we turned off statement recovery across a few Java library packages in Wala on all benchmarks.
%
We ran the above implementation using the incremental solving mode of Z3 using the bitvector theory.
%
The incremental solving mode provides only the last constructed constraint to the solver instead of passing the entire
path condition every time a query is to be solved.
%
Since path-merging can create large formulas in the path condition, the incremental solving mode provided a crucial
benefit in reducing the number of times large formulas had to be passed to the solver.
%
\subsection{Evaluation}
%
In order to evaluate the performance of \tool, we used the following nine benchmarking programs commonly used to
evaluate symbolic execution performance.
%
Eight of these programs were provided by Wang et al.~\cite{dgse} which also includes a translation of the
Siemens suite to Java.
%
(1) Wheel Brake System (WBS)~\cite{yang2014directed} is a synchronous reactive
component developed to make aircraft brake safely when taxing, landing, and during a rejected take-off.
%
(2) Traffic Collision Avoidance System (TCAS) is part of a suite of programs commonly referred to as the Siemens
suite~\cite{siemens-benchmarks}. TCAS is a system that maintains altitude separation between aircraft to avoid mid-air
collisions.
%
(3) Replace is another program that\rq s part of the Siemens suite. Replace searches for a pattern in a given input and
replaces it with another input string.
%
(4) NanoXML is an XML Parser written in Java which consists of 129 procedures and 4608 lines of code.
%
(5) Siena~(Scalable Internet Event Notification Architecture) is an Internet-scale event notification middleware for
distributed event-based applications~\cite{siena} which consists of 94 procedures and 1256 lines of code.
%
(6) Schedule2 is a priority scheduler which consists of 27 procedures and 306 lines of code.
%
(7) PrintTokens2 is a lexical analyzer which consists of 30 procedures and 570 lines of code.
%
(8) ApacheCLI~\cite{apachecli} provides an API for parsing command lines options passed to programs.
It consists of 183 procedures and 3612 lines of code.
%
(9) MerArbiter models a flight software component of NASA JPL\rq s Mars Exploration Rovers.
%
%It was originally modeled in Simulink/Stateflow and automatically translated into Java using the Polyglot framework.
%
We used the version made
available by Yang et al.~\cite{memoise}. This benchmark consists of 268 classes, 553 methods, 4697 lines of code
including the Polyglot framework.

We first ran each of these benchmarks using SPF with increasing number of symbolic inputs and obtained the most number of inputs
with which SPF finished complete exploration of each benchmark within a 24 hour time budget.
%
We then ran each benchmark with this number of symbolic inputs with \tool.
%
This evaluation allowed us to check if \tool\ is faster than SPF at achieving complete path exploration of each benchmark.
%
Next, we used the fastest mode of \tool\ to check if it could explore the benchmark with even more symbolic inputs within
the same 12 hour time budget.\vaibhav{Figure out if these results need to be reported}
%
We report results from this evaluations for each benchmark in Table~\ref{table:results-all-mode5}
%
Since Java Ranger relies on a prior static analysis to construct region summaries, we report the time taken to statically
analyze all the code in each of the benchmarks in column ``static analysis time (sec)'' in
Table~\ref{table:results-all-mode5}.
%
We found that the total time required for static analyis is roughly proportional to the size of the benchmark.
%
While static analysis performance can cause \tool\ to be slower on benchmarks with a small number of execution
paths, we observed that the cost of static analysis gets amortized as the number of execution paths increases.
%
\input{tables/results-all-mode5}
%
Table~\ref{table:results-all-modes5} shows that \tool\ achieves a significant speed-up over SPF with
5~(WBS, TCAS, NanoXML, ApacheCLI, MerArbiter) of the 9 benchmarks in terms of both running time and number of
execution paths.
%
Of the remaining four benchmarks, \tool\ also achieves a modest 22\% reduction in running time and 34\% reduction
in the number of execution paths with the PrintTokens2 benchmark.
%
\tool\ has the same performance as SPF on Siena and Schedule2 with a minor overhead in running time that comes from
\tool\rq s lookup of a region summary for every executed branch instruction and recording of instantiation-time metrics.
%
We restrict our results with Siena to 7 symbolic inputs because 6 is the most number of symbolic inputs for which
SPF finishes complete path exploration within a 24 hour time budget.
%
On running Siena, the overhead of \tool\ results from running into concrete branch instructions that
\tool\ could have summarized, had these branches been symbolic.
%
In the replace benchmark, while \tool\ reduces the number of execution paths by about 89\%, it incurs an increase in
execution time due to most region instantiations not being beneficial.
%
On manually investigating the set of instantiated regions in replace, we found that the outputs of most regions were
being branched on later in the code causing the benefit from more instantiations to be lost.
%
\vaibhav{Running an automated analysis to check if there is a subset of regions that is most beneficial}

\tool\ is able to summarize the entire step function of WBS and TCAS into a single execution path.
%
In case of WBS, \tool\ summarizes a multi-path region that consists of 9 branches.
%
In case of TCAS, \tool\ uses 28 method summaries in each step of TCAS, many of which summarize multiple return values
into a single formula that represents all the feasible return values of the method.
%
While SPF does not finish more than 5 steps of WBS and 2 steps of TCAS within 12 hours, \tool\ finishes 10 steps of both
benchmarks within 59 seconds and 5.6 seconds respectively.

On the NanoXML benchmark, \tool\ finds several opportunities for execution path count reduction on account of the
NanoXML benchmark having several methods with multi-path regions that have a control-flow returning instruction on every
branch side.
%
With mode 5 of \tool\ converting such multiple control-flow returning exit points regions into a single control-flow
returning exit point, \tool\ is able to use more than 27,000 method summaries when running NanoXML with 8 symbolic
inputs and finish in 7.3 hours while vanilla SPF~(which is the same as mode 1 of \tool)
times out in 12 hours.

On the ApacheCLI benchmark, the most significant benefit is introduced in mode 2 of \tool.
%
Modes 4, 5 cause an increase in execution path count and running time but still give a significant reduction over
mode 1.
%
The increase in running time in modes 4 and 5 results from \tool\rq s use of the solver to check if the single-path cases
in modes 4 and 5 are feasible.
%
In the future, we plan to use a counter-example cache to reduce the use of a solver to check the feasibility of these
single-path cases.

In the MerArbiter benchmark, while the most significant benefit is introduced in mode 2 of \tool, the benefit in terms of
both execution path count and running time remains the same in modes 3, 4, and 5.
%
All the multi-path regions that SPF~(which is mode 1 in \tool) needs to branch on but are summarized by \tool\ are small
regions that compute a boolean value based on a symbolic branch and write it to the stack as an operand to be used
by the following return instruction.
%
Most of these multi-path regions lie inside several levels of nested classes and field references that necessitate
a fixed-point computation over the field substitution and constant propagation transformations.
%
\tool\ summarizes such multi-path regions and does 464,000 instantiations with 7 steps of MerArbiter, with more than
319,000 instantiations needing more than 8 iterations of the fixed-point computation.