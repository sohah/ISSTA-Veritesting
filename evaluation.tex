\section{Evaluation}
\label{sec:results}
\subsection{Experimental Setup}
%
We implemented the above mentioned transformations as a wrapper around the Symbolic PathFinder~\cite{spf} tool.
%
To make use of region summaries in Symbolic PathFinder, we use an existing feature of SPF named \textit{listener}.
%
A listener is a method defined within SPF that is called for every bytecode instruction executed by SPF.
%
\tool\ adds a path merging listener to SPF that, on every program location to be executed, checks if the next
instruction is a conditional branch instruction with at least one symbolic operand.
%
On finding such a symbolic branch condition, \tool\ attempts to compute a static summary of all multi-path
regions in the method which contains the current program location.
%
After this Just-In-Time static analysis, if \tool\ summarized the multi-path region that begins at the current program
location, \tool\ computes the canonical region corresponding to the current program location by reading inputs from
and writing outputs to the stack and the heap.
%
Finally, it conjuncts the canonical region summary with the path condition and resumes symbolic execution at the
bytecode offset of the end of the region.
%
\tool\ wraps around SPF and can be configured to either run SPF without any path merging or run SPF with the
following four path-merging features enabled.

(1) \tool\ only transforms multi-path regions with a single exit point to their canonical form.
This includes multi-path regions that have local, stack, field, or array outputs.
%
\tool\ substitutes local inputs into the Ranger IR representation of the multi-path region, and constructs SSA form
Ranger IR for all field and array accesses in the region using its runtime context.
%
The SSA form representation of all field and array accesses allows the Ranger IR to be simplified uniformly across all
variable types which reduces the size of the region summary and improves performance.
%
While our current implementation of \tool\ cannot transform summaries with symbolic object and array
references, it is capable of summarizing reads and writes to arrays with symbolic indices.
%
(2) \tool\ uses multi-path region
summaries that make method calls which have also been statically summarized.
%
Method summaries are inlined into
the multi-path region summary based on the dynamic type of the method.
%
(3) \tool\ uses single-path cases to allow regions to have more than one exit point.
%
These exit points take the form of new object allocations and exceptional behavior present in the region.
%
(4) \tool\ converts multiple exit points that return
control flow from the region to its caller into a single control flow-returning exit point.
%
This feature allows summarization of multiple {\tt return} instructions in a region into a single control-flow
returning exit point.
%
Instead of a single return value, such an exit point returns a formula to its caller, which predicates
each return value on its corresponding condition in the region.

We used the control-flow graph recovered by Wala~\cite{Wala} to bootstrap our static statement recovery process.
%
%While we found our static statement recovery was capable of summarizing thousands of regions in Java library code, many
%of these summaries could not be instantiated due to JPF\rq s use of native peers~\cite{jpf-mji}.
%
%To avoid these unnecessary instantiation failures and target our static statement recovery towards the benchmark code,
%we turned off statement recovery across a few Java library packages in Wala on all benchmarks.
%
We ran the above implementation using the incremental solving mode of Z3 using the bitvector theory.
%
The incremental solving mode provides only the last constructed constraint to the solver instead of passing the entire
path condition every time a query is to be solved.
%
Since path-merging can create large formulas in the path condition, the incremental solving mode provided a crucial
benefit in reducing the number of times large formulas had to be passed to the solver.
%
\subsection{Evaluation}
%
In order to evaluate the performance of \tool, we used the following nine benchmarking programs commonly used to
evaluate symbolic execution performance.
%
Eight of these programs were provided by Wang et al.~\cite{dgse} which also includes a translation of the
Siemens suite to Java.
%
(1) Wheel Brake System (WBS)~\cite{yang2014directed} is a synchronous reactive
component developed to make aircraft brake safely when taxing, landing, and during a rejected take-off.
%
(2) Traffic Collision Avoidance System (TCAS) is part of a suite of programs commonly referred to as the Siemens
suite~\cite{siemens-benchmarks}. TCAS is a system that maintains altitude separation between aircraft to avoid mid-air
collisions.
%
(3) Replace is another program that\rq s part of the Siemens suite. Replace searches for a pattern in a given input and
replaces it with another input string.
%
(4) NanoXML is an XML Parser written in Java which consists of 129 procedures and 4608 lines of code.
%
(5) Siena~(Scalable Internet Event Notification Architecture) is an Internet-scale event notification middleware for
distributed event-based applications~\cite{siena} which consists of 94 procedures and 1256 lines of code.
%
(6) Schedule2 is a priority scheduler which consists of 27 procedures and 306 lines of code.
%
(7) PrintTokens2 is a lexical analyzer which consists of 30 procedures and 570 lines of code.
%
(8) ApacheCLI~\cite{apachecli} provides an API for parsing command lines options passed to programs.
It consists of 183 procedures and 3612 lines of code.
%
(9) MerArbiter models a flight software component of NASA JPL\rq s Mars Exploration Rovers.
%
%It was originally modeled in Simulink/Stateflow and automatically translated into Java using the Polyglot framework.
%
We used the version made
available by Yang et al.~\cite{memoise}. This benchmark consists of 268 classes, 553 methods, 4697 lines of code
including the Polyglot framework.

We first ran each of these benchmarks using SPF with increasing number of symbolic inputs and obtained the most number
of symbolic inputs with which SPF finished complete exploration of each benchmark within a 24 hour time budget.
%
We then ran each benchmark with this number of symbolic inputs with \tool.
%
This evaluation allowed us to check if \tool\ is faster than SPF at achieving complete path exploration of each benchmark.
%
%Next, we used the fastest mode of \tool\ to check if it could explore the benchmark with even more symbolic inputs within
%the same 12 hour time budget.\vaibhav{Figure out if these results need to be reported}
%
We report results from this evaluation for each benchmark in Table~\ref{table:results-all-mode5}
%
%While static analysis performance can cause \tool\ to be slower on benchmarks with a small number of execution
%paths, we observed that the cost of static analysis gets amortized as the number of execution paths increases.
%
\input{tables/results-all-mode5}
%
\input{tables/comparison-tables}
%
Table~\ref{table:results-all-modes5} shows that \tool\ achieves a significant speed-up over SPF with
5~(WBS, TCAS, NanoXML, ApacheCLI, MerArbiter) of the 9 benchmarks in terms of both running time and number of
execution paths.
%
\tool\ also achieves a modest 22\% reduction in running time and 34\% reduction
in the number of execution paths with the PrintTokens2 benchmark.

\tool\ is able to summarize the entire step function of WBS and TCAS into a single execution path.
%
This step functions of WBS and TCAS take 3 and 12 symbolic inputs respectively.
%
In WBS, \tool\ summarizes multi-path regions with deeply nested {\tt if} bytecode instructions, in one case
summarizing a region that consisted of 9 branches nested within one another.
%
In TCAS, \tool\ uses 28 method summaries in each step of TCAS, many of which summarize multiple return values
into a single formula that represents all the feasible return values of the method.
%
While SPF does not finish more than 5 steps of WBS and 2 steps of TCAS within 24 hours, \tool\ finishes 10 steps of both
benchmarks within 2.81 seconds and 1.41 seconds respectively.

In the replace benchmark, while \tool\ reduces the number of execution paths by about 88\%, it incurs an increase in
execution time.
%
This increase occurs even when \tool\ transforms 20 distinct regions into 7334 canonical region summaries.
%
On manually investigating the set of instantiated regions in replace, we found that the outputs of most of these
regions were being branched on later in the code causing the benefit from path-merging to be lost.
%
In order to test this hypothesis, we ran an automated evaluation where we restricted \tool\ to only a subset of
regions.
%
First, we determined the most number of symbolic inputs with which \tool\ could explore all paths in replace in less
than a minute.
%
We found this number to be 6 symbolic inputs which took \tool\ about 37 seconds while using 14 regions.
%
Next, we constructed a list of region subsets sorted in increasing order of the subset size.
%
This list began with 14 region subsets, each containing one region, and ended with a single set containing all 14 regions.
%
Finally, we ran \tool\ with every region subset in this list, where \tool\ was allowed to only canonicalize regions
within a given subset.
%
After running this evaluation for 96 hours, we found that all possible region subsets containing up to 4 regions had
been tested.
%
But, no region subset up to 4 regions in size resulted with a reduction in the running time and number of execution
paths.
%
While it is possible that there is a specific set of regions in the replace benchmark that provides the most benefit
from path-merging, our automated evaluation and a manual investigation did not reveal what such a set of regions might be.
%
In the future, we plan to integrate a query count estimated heuristic of the kind proposed by
Kuznetsov et al.~\cite{kuznetsov} to canonicalize only a beneficial set of regions in the replace benchmark.

On the NanoXML benchmark, \tool\ finds several opportunities for execution path count reduction on account of the
NanoXML benchmark having several methods with multi-path regions that have a control-flow returning instruction on every
branch side.
%
Since \tool\ can convert such multiple control-flow returning exit points regions into a single control-flow
returning exit point, \tool\ is able to inline more than 8,000 method summaries when running NanoXML with 8 symbolic
inputs and finish in about 8 hours while vanilla SPF needs about 18 hours to complete the same exploration.

\tool\ has the same performance as SPF on Siena and Schedule2 with a minor overhead in running time that comes from
\tool\rq s lookup of a region summary for every executed branch instruction and recording of metrics.
%
We restrict our results with Siena to 7 symbolic inputs because 7 is the most number of symbolic inputs for which
SPF finishes complete path exploration within a 24 hour time budget.
%
On running Siena, the overhead of \tool\ results from running into concrete branch instructions that
\tool\ could have summarized, had these branches been symbolic.

In the PrintTokens2 benchmark, \tool\ uses 4 distinct regions, 2 of which involve summarizing multi-path regions which
have a {\tt return} instruction at the end of every path in the region.
%
Being able to summarize multiple control-flow returning exit points into a single such exit point proves to be a crucial
feature in \tool\ for this benchmark.

The ApacheCLI benchmark takes 9 inputs, the first 8 are 1-byte inputs used to construct command-line options and
the last input controls whether ApacheCLI should stop on encountering an invalid option input.
%
Since the 9th input is different from the first 8, we ran ApacheCLI with the first 6 inputs and the 9th input
made symbolic.
%
\tool\ finishes exploration with this setup of ApacheCLI in about 1.5 hours whereas SPF finishes exploration in about 9
hours as shown in Table~\ref{table:results-all-mode5}
%
When we ran SPF on ApacheCLI with the first 7 inputs and the 9th input made symbolic, it was unable to complete
exploration within 24 hours.
%
But, \tool\ can complete this exploration in about 15 hours.

In the MerArbiter benchmark, while the most significant benefit is introduced in mode 2 of \tool, the benefit in terms of
both execution path count and running time remains the same in modes 3, 4, and 5.
%
All the multi-path regions that SPF~(which is mode 1 in \tool) needs to branch on but are summarized by \tool\ are small
regions that compute a boolean value based on a symbolic branch and write it to the stack as an operand to be used
by the following return instruction.
%
Most of these multi-path regions lie inside several levels of nested classes and field references that necessitate
a fixed-point computation over the field substitution and constant propagation transformations.
%
\tool\ summarizes such multi-path regions and does 464,000 instantiations with 7 steps of MerArbiter, with more than
319,000 instantiations needing more than 8 iterations of the fixed-point computation.